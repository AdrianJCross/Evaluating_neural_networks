{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'ascii' codec can't decode byte 0x90 in position 614: ordinal not in range(128)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-7dde001e9c39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmnist_loader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtraining_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mmnist_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/UTK_PhD/Machine_learning_fall_2019/project_3/src/mnist_loader.py\u001b[0m in \u001b[0;36mload_data_wrapper\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0mturn\u001b[0m \u001b[0mout\u001b[0m \u001b[0mto\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmost\u001b[0m \u001b[0mconvenient\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0muse\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mour\u001b[0m \u001b[0mneural\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     code.\"\"\"\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0mtr_d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mva_d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mte_d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m     \u001b[0mtraining_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m784\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtr_d\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0mtraining_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvectorized_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtr_d\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/UTK_PhD/Machine_learning_fall_2019/project_3/src/mnist_loader.py\u001b[0m in \u001b[0;36mload_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m     \"\"\"\n\u001b[1;32m     42\u001b[0m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/mnist.pkl.gz'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mtraining_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcPickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'ascii' codec can't decode byte 0x90 in position 614: ordinal not in range(128)"
     ]
    }
   ],
   "source": [
    "import mnist_loader\n",
    "training_data, validation_data, test_data = mnist_loader.load_data_wrapper()\n",
    "import network2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_accuracy_epochs(name,ev_accuracy,train_accuracy): #plots ev and training accuracy against epoch no \n",
    "    x=range(1,len(train_accuracy)+1)\n",
    "    ev_accuracy=np.divide(ev_accuracy,10000.0)\n",
    "    train_accuracy=np.divide(train_accuracy,50000.0)\n",
    "    savename='plots/'+name+'_accuracy.png'\n",
    "    plt.figure()\n",
    "    ev,=plt.plot(x,ev_accuracy,label='ev')\n",
    "    train,=plt.plot(x,train_accuracy,label='train')\n",
    "    plt.xlabel('epoch number')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.title(name+ ' accuracy')\n",
    "    plt.legend([ev,train],['testing dataset','training dataset'])\n",
    "    plt.savefig(savename)\n",
    "    \n",
    "def plot_cost_epochs(name,ev_cost,training_cost): #plots ev and training cost against epoch no \n",
    "    x=range(1,len(train_cost)+1)\n",
    "    savename='plots/'+name+'_cost.png'\n",
    "    plt.figure()\n",
    "    ev,=plt.plot(x,ev_cost)\n",
    "    train,=plt.plot(x,train_cost)\n",
    "    plt.xlabel('epoch number')\n",
    "    plt.ylabel('cost')\n",
    "    plt.title(name+' cost')\n",
    "    plt.legend([ev,train],['testing dataset','training dataset'])\n",
    "    plt.savefig(savename)\n",
    "    \n",
    "net = network2.Network([784, 30, 10])\n",
    "#default paramaters are epochs=10, mini batch size=10, learning rate=3, number of neurons=30 \n",
    "#each parameters is varied keeping the other parameters as defaults.\n",
    "mini_batch_size_def=10\n",
    "eta_def=3.0\n",
    "lmbda_def=0.0\n",
    "epochs_def=10\n",
    "\n",
    "#default\n",
    "ev_cost,ev_accuracy,train_cost,train_accuracy=net.SGD(training_data, epochs=epochs_def, mini_batch_size=mini_batch_size_def, eta=eta_def,lmbda=lmbda_def,evaluation_data=test_data,monitor_evaluation_cost=True,\n",
    "            monitor_evaluation_accuracy=True,\n",
    "            monitor_training_cost=True,\n",
    "            monitor_training_accuracy=True)\n",
    "plot_accuracy_epochs('default',ev_accuracy,train_accuracy)\n",
    "plot_cost_epochs('default',ev_cost,train_cost)\n",
    "\\end{lstlisting}\n",
    "\\subsection{Varying training parameter}\n",
    "\\begin{lstlisting}[language=Python]\n",
    "#variation of training parameter eta \n",
    "net = network2.Network([784, 30, 10])\n",
    "mini_batch_size_def=10\n",
    "lmbda_def=0.0\n",
    "epochs_def=10\n",
    "eta=[0.01,0.1,1,10,100]\n",
    "labels=[None]*len(eta)\n",
    "for i in range(0,len(eta)):\n",
    "    labels[i]='eta='+str(eta[i])\n",
    "plt.figure()\n",
    "fig, (ax1,ax2)=plt.subplots(1,2)\n",
    "fig.tight_layout()\n",
    "#fig.suptitle('Training paramater variation')\n",
    "ax1.set_title('accuracy')\n",
    "ax1.set(xlabel='epoch',ylabel='accuracy')\n",
    "ax2.set_title('cost')\n",
    "ax2.set(xlabel='epoch',ylabel='cost')\n",
    "x=range(1,len(train_cost)+1)\n",
    "\n",
    "for i in range(0,len(eta)):\n",
    "    ev_cost,ev_accuracy,train_cost,train_accuracy=net.SGD(training_data, epochs=epochs_def, mini_batch_size=mini_batch_size_def, eta=eta[i],lmbda=lmbda_def,evaluation_data=test_data,monitor_evaluation_cost=True,\n",
    "            monitor_evaluation_accuracy=True,\n",
    "            monitor_training_cost=True,\n",
    "            monitor_training_accuracy=True) \n",
    "    ax1.plot(x,ev_accuracy,label=labels[i])\n",
    "    ax2.plot(x,ev_cost)\n",
    "    plot_accuracy_epochs('training parameter='+str(eta[i]),ev_accuracy,train_accuracy)\n",
    "    plot_cost_epochs('training parameter='+str(eta[i]),ev_cost,train_cost)\n",
    "fig.legend()\n",
    "fig.savefig('plots/eta.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#variation of training parameter eta \n",
    "net = network2.Network([784, 30, 10])\n",
    "mini_batch_size_def=10\n",
    "lmbda_def=0.0\n",
    "epochs_def=10\n",
    "eta=[0.01,0.1,1,10,100]\n",
    "labels=[None]*len(eta)\n",
    "for i in range(0,len(eta)):\n",
    "    labels[i]='eta='+str(eta[i])\n",
    "plt.figure()\n",
    "fig, (ax1,ax2)=plt.subplots(1,2)\n",
    "fig.tight_layout()\n",
    "#fig.suptitle('Training paramater variation')\n",
    "ax1.set_title('accuracy')\n",
    "ax1.set(xlabel='epoch',ylabel='accuracy')\n",
    "ax2.set_title('cost')\n",
    "ax2.set(xlabel='epoch',ylabel='cost')\n",
    "x=range(1,len(train_cost)+1)\n",
    "\n",
    "for i in range(0,len(eta)):\n",
    "    ev_cost,ev_accuracy,train_cost,train_accuracy=net.SGD(training_data, epochs=epochs_def, mini_batch_size=mini_batch_size_def, eta=eta[i],lmbda=lmbda_def,evaluation_data=test_data,monitor_evaluation_cost=True,\n",
    "            monitor_evaluation_accuracy=True,\n",
    "            monitor_training_cost=True,\n",
    "            monitor_training_accuracy=True) \n",
    "    ax1.plot(x,ev_accuracy,label=labels[i])\n",
    "    ax2.plot(x,ev_cost)\n",
    "    plot_accuracy_epochs('training parameter='+str(eta[i]),ev_accuracy,train_accuracy)\n",
    "    plot_cost_epochs('training parameter='+str(eta[i]),ev_cost,train_cost)\n",
    "fig.legend()\n",
    "fig.savefig('plots/eta.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'ascii' codec can't decode byte 0x90 in position 614: ordinal not in range(128)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-5031c9dcc768>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtraining_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmnist_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/UTK_PhD/Machine_learning_fall_2019/project_3/src/mnist_loader.py\u001b[0m in \u001b[0;36mload_data_wrapper\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0mturn\u001b[0m \u001b[0mout\u001b[0m \u001b[0mto\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmost\u001b[0m \u001b[0mconvenient\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0muse\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mour\u001b[0m \u001b[0mneural\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     code.\"\"\"\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0mtr_d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mva_d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mte_d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m     \u001b[0mtraining_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m784\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtr_d\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0mtraining_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvectorized_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtr_d\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/UTK_PhD/Machine_learning_fall_2019/project_3/src/mnist_loader.py\u001b[0m in \u001b[0;36mload_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m     \"\"\"\n\u001b[1;32m     42\u001b[0m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/mnist.pkl.gz'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mtraining_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcPickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'ascii' codec can't decode byte 0x90 in position 614: ordinal not in range(128)"
     ]
    }
   ],
   "source": [
    "#variation of mini batch\n",
    "net = network2.Network([784, 30, 10])\n",
    "mini_batch_size=[5,10,15,20,25,30]\n",
    "lmbda_def=0.0\n",
    "epochs_def=10\n",
    "eta_def=3.0\n",
    "labels=[None]*len(mini_batch_size)\n",
    "for i in range(0,len(mini_batch_size)):\n",
    "    labels[i]='mini batch size='+str(mini_batch_size[i])\n",
    "plt.figure()\n",
    "fig, (ax1,ax2)=plt.subplots(1,2)\n",
    "fig.tight_layout()\n",
    "#fig.suptitle('Training paramater variation')\n",
    "ax1.set_title('accuracy')\n",
    "ax1.set(xlabel='epoch',ylabel='accuracy')\n",
    "ax2.set_title('cost')\n",
    "ax2.set(xlabel='epoch',ylabel='cost')\n",
    "x=range(1,len(train_cost)+1)\n",
    "for i in range(0,len(mini_batch_size)):\n",
    "    ev_cost,ev_accuracy,train_cost,train_accuracy=net.SGD(training_data, epochs=epochs_def, mini_batch_size=mini_batch_size[i], eta=eta_def,lmbda=lmbda_def,evaluation_data=test_data,monitor_evaluation_cost=True,\n",
    "            monitor_evaluation_accuracy=True,\n",
    "            monitor_training_cost=True,\n",
    "            monitor_training_accuracy=True) \n",
    "    ax1.plot(x,ev_accuracy,label=labels[i])\n",
    "    ax2.plot(x,ev_cost)\n",
    "    plot_accuracy_epochs('mini batch size='+str(mini_batch_size[i]),ev_accuracy,train_accuracy)\n",
    "    plot_cost_epochs('mini batch size='+str(mini_batch_size[i]),ev_cost,train_cost)\n",
    "fig.legend()\n",
    "fig.savefig('plots/mini_batch.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#variation of number of neurons\n",
    "neuron_size=[5,10,15,20,25,30]\n",
    "mini_batch_size_def=10\n",
    "lmbda_def=0.0\n",
    "epochs_def=10\n",
    "eta_def=3.0\n",
    "labels=[None]*len(neuron_size)\n",
    "for i in range(0,len(neuron_size)):\n",
    "    labels[i]='no of neurons='+str(neuron_size[i])\n",
    "plt.figure()\n",
    "fig, (ax1,ax2)=plt.subplots(1,2)\n",
    "fig.tight_layout()\n",
    "#fig.suptitle('Training paramater variation')\n",
    "ax1.set_title('accuracy')\n",
    "ax1.set(xlabel='epoch',ylabel='accuracy')\n",
    "ax2.set_title('cost')\n",
    "ax2.set(xlabel='epoch',ylabel='cost')\n",
    "x=range(1,len(train_cost)+1)\n",
    "for i in range(0,len(neuron_size)):\n",
    "    \n",
    "    net = network2.Network([784, neuron_size[i], 10])\n",
    "    ev_cost,ev_accuracy,train_cost,train_accuracy=net.SGD(training_data, epochs=10, mini_batch_size=mini_batch_size_def, eta=eta_def,lmbda=lmbda_def,evaluation_data=test_data,monitor_evaluation_cost=True,\n",
    "            monitor_evaluation_accuracy=True,\n",
    "            monitor_training_cost=True,\n",
    "            monitor_training_accuracy=True) \n",
    "    ax1.plot(x,ev_accuracy,label=labels[i])\n",
    "    ax2.plot(x,ev_cost)\n",
    "    plot_accuracy_epochs('neuron size='+str(neuron_size[i]),ev_accuracy,train_accuracy)\n",
    "    plot_cost_epochs('neuron size='+str(neuron_size[i]),ev_cost,train_cost)\n",
    "fig.legend()\n",
    "fig.savefig('plots/neuron_size.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
